# GuÃ­a de ImplementaciÃ³n: Trazabilidad y AuditorÃ­a de Datos

## ğŸ“‹ Resumen Ejecutivo

Este documento describe la implementaciÃ³n de un **sistema estandarizado de trazabilidad y auditorÃ­a de datos** para el pipeline de trading. La nueva estructura reemplaza el sistema legacy de mÃºltiples columnas con una **columna Ãºnica estandarizada `data_origin`** que proporciona trazabilidad completa del origen y calidad de cada registro.

## ğŸ¯ Objetivos Implementados

âœ… **EstandarizaciÃ³n**: Una sola columna `data_origin` con valores catalogados  
âœ… **Trazabilidad completa**: Origen, mÃ©todo de captura, calidad y procesamiento  
âœ… **ValidaciÃ³n robusta**: VerificaciÃ³n automÃ¡tica de valores permitidos  
âœ… **MigraciÃ³n automÃ¡tica**: ConversiÃ³n de datos legacy a nueva estructura  
âœ… **Reportes avanzados**: AnÃ¡lisis detallado de calidad y origen de datos  
âœ… **Formato de tiempo estÃ¡ndar**: UTC con zona horaria explÃ­cita  

## ğŸ—ï¸ Arquitectura de la Nueva Estructura

### **Columna Principal: `data_origin`**

La columna `data_origin` contiene valores estandarizados que codifican toda la informaciÃ³n de trazabilidad:

```
FORMATO: [TIMEFRAME]_[TIPO]_[METODO]
Ejemplos:
- M5_NATIVO          â†’ Datos M5 capturados directamente
- M5_AGREGADO_M1     â†’ Datos M1 agregados a M5
- M5_IMPUTADO_BROWNIAN â†’ Datos imputados con Brownian Bridge
- TICKS_NATIVO       â†’ Datos de ticks capturados directamente
```

### **CatÃ¡logo de Valores Permitidos**

#### **Datos Nativos (Captura Directa)**
| Valor | DescripciÃ³n | Quality Score | CategorÃ­a |
|-------|-------------|---------------|-----------|
| `M5_NATIVO` | Datos capturados directamente en M5 | 1.0 | native |
| `M1_NATIVO` | Datos capturados directamente en M1 | 0.95 | native |
| `M10_NATIVO` | Datos capturados directamente en M10 | 0.85 | native |
| `M15_NATIVO` | Datos capturados directamente en M15 | 0.80 | native |
| `M20_NATIVO` | Datos capturados directamente en M20 | 0.75 | native |
| `M30_NATIVO` | Datos capturados directamente en M30 | 0.70 | native |
| `H1_NATIVO` | Datos capturados directamente en H1 | 0.65 | native |
| `TICKS_NATIVO` | Datos de ticks capturados directamente | 0.98 | native |

#### **Datos Agregados (Resampleados)**
| Valor | DescripciÃ³n | Quality Score | CategorÃ­a |
|-------|-------------|---------------|-----------|
| `M5_AGREGADO_M1` | Datos M1 agregados a M5 | 0.95 | aggregated |
| `M5_AGREGADO_M10` | Datos M10 agregados a M5 | 0.85 | aggregated |
| `M5_AGREGADO_M15` | Datos M15 agregados a M5 | 0.80 | aggregated |
| `M5_AGREGADO_M20` | Datos M20 agregados a M5 | 0.75 | aggregated |
| `M5_AGREGADO_M30` | Datos M30 agregados a M5 | 0.70 | aggregated |
| `M5_AGREGADO_H1` | Datos H1 agregados a M5 | 0.65 | aggregated |
| `M5_AGREGADO_TICKS` | Datos de ticks agregados a M5 | 0.98 | aggregated |

#### **Datos Imputados (SintÃ©ticos)**
| Valor | DescripciÃ³n | Quality Score | CategorÃ­a |
|-------|-------------|---------------|-----------|
| `M5_IMPUTADO_BROWNIAN` | Datos imputados usando Brownian Bridge | 0.7 | imputed |
| `M5_IMPUTADO_INTERPOLADO` | Datos imputados usando interpolaciÃ³n lineal | 0.6 | imputed |
| `M5_IMPUTADO_SIMPLE` | Datos imputados usando mÃ©todo simple | 0.5 | imputed |
| `M5_IMPUTADO_GAUSSIANO` | Datos imputados usando distribuciÃ³n gaussiana | 0.65 | imputed |

#### **Otros Tipos**
| Valor | DescripciÃ³n | Quality Score | CategorÃ­a |
|-------|-------------|---------------|-----------|
| `M5_FUERA_DE_HORARIO` | Datos fuera del horario de mercado | 0.3 | outside_market |
| `M5_FALLBACK` | Datos capturados usando mÃ©todo de respaldo | 0.8 | fallback |
| `DESCONOCIDO` | Origen de datos desconocido | 0.0 | unknown |

## ğŸ”§ ImplementaciÃ³n TÃ©cnica

### **1. Constantes y ConfiguraciÃ³n**

```python
# pipelines/01_capture/config/constants.py

# CatÃ¡logo de valores permitidos
DATA_ORIGINS = {
    'M5_NATIVO': {
        'description': 'Datos capturados directamente en M5 (mÃ¡xima calidad)',
        'quality_score': 1.0,
        'category': 'native'
    },
    # ... mÃ¡s valores
}

# Lista para validaciÃ³n
DATA_ORIGIN_VALUES = list(DATA_ORIGINS.keys())

# Mapeo de mÃ©todos de captura
CAPTURE_METHOD_TO_DATA_ORIGIN = {
    'rates_range': {
        'M5': 'M5_NATIVO',
        'M1': 'M1_NATIVO',
        # ...
    }
}
```

### **2. Gestor de Trazabilidad**

```python
# pipelines/01_capture/utils/data_traceability.py

class DataTraceabilityManager:
    def assign_data_origin(self, df, capture_method, source_timeframe, 
                          is_imputed=False, imputation_method=None):
        """Asignar data_origin estandarizado"""
        
    def validate_data_origin(self, df):
        """Validar valores de data_origin"""
        
    def convert_legacy_data_flags(self, df):
        """Migrar datos legacy a nueva estructura"""
```

### **3. IntegraciÃ³n en Procesamiento**

```python
# pipelines/01_capture/data/processing.py

def brownian_bridge_imputation_numba_tracked(df, quality_tracker):
    # Inicializar gestor de trazabilidad
    traceability_manager = DataTraceabilityManager()
    
    # ... lÃ³gica de imputaciÃ³n ...
    
    # Asignar data_origin estandarizado
    imputed_df = traceability_manager.assign_data_origin(
        imputed_df, 
        capture_method='brownian_bridge',
        source_timeframe='imputed',
        is_imputed=True,
        imputation_method='brownian_bridge'
    )
```

## ğŸ“Š Estructura de Datos Final

### **Columnas Requeridas**
```python
REQUIRED_COLUMNS = [
    'time',           # Timestamp en UTC
    'open',           # Precio de apertura
    'high',           # Precio mÃ¡ximo
    'low',            # Precio mÃ­nimo
    'close',          # Precio de cierre
    'data_origin'     # Origen estandarizado del dato
]
```

### **Columnas Opcionales**
```python
OPTIONAL_COLUMNS = [
    'tick_volume',    # Volumen de ticks
    'spread',         # Spread
    'real_volume',    # Volumen real
    'quality_score'   # PuntuaciÃ³n de calidad (0.0-1.0)
]
```

### **Formato de Tiempo EstÃ¡ndar**
```python
TIME_FORMAT_CONFIG = {
    'display_format': '%Y-%m-%d %H:%M:%S',
    'display_format_with_tz': '%Y-%m-%d %H:%M:%S%z',
    'default_timezone': 'UTC'
}
```

## ğŸ”„ MigraciÃ³n de Datos Legacy

### **Columnas Legacy a Migrar**
- `data_flag` â†’ `data_origin`
- `source_timeframe` â†’ InformaciÃ³n codificada en `data_origin`
- `capture_method` â†’ InformaciÃ³n codificada en `data_origin`

### **Script de MigraciÃ³n**

```bash
# Validar archivos existentes
python pipelines/01_capture/utils/validate_traceability.py \
    --input data/ \
    --action validate \
    --report validation_report.json

# Migrar archivos legacy
python pipelines/01_capture/utils/validate_traceability.py \
    --input data/ \
    --output data_migrated/ \
    --action migrate \
    --pattern "*.parquet"
```

### **Mapeo de MigraciÃ³n**

```python
# Ejemplos de migraciÃ³n automÃ¡tica
'data_flag': 'real_m5' + 'source_timeframe': 'M5' 
    â†’ 'data_origin': 'M5_NATIVO'

'data_flag': 'aggregated_from_m1' + 'source_timeframe': 'M1'
    â†’ 'data_origin': 'M5_AGREGADO_M1'

'data_flag': 'imputed_brownian' + 'capture_method': 'brownian_bridge'
    â†’ 'data_origin': 'M5_IMPUTADO_BROWNIAN'
```

## ğŸ“ˆ Reportes de Calidad Mejorados

### **AnÃ¡lisis por CategorÃ­a**
```json
{
  "category_analysis": {
    "native": {
      "count": 150000,
      "percentage": 75.0,
      "description": "Datos capturados directamente"
    },
    "aggregated": {
      "count": 40000,
      "percentage": 20.0,
      "description": "Datos resampleados"
    },
    "imputed": {
      "count": 10000,
      "percentage": 5.0,
      "description": "Datos sintÃ©ticos"
    }
  }
}
```

### **DistribuciÃ³n por Origen**
```json
{
  "origin_breakdown": {
    "M5_NATIVO": {
      "count": 120000,
      "percentage": 60.0,
      "description": "Datos capturados directamente en M5",
      "category": "native"
    },
    "M5_AGREGADO_M1": {
      "count": 30000,
      "percentage": 15.0,
      "description": "Datos M1 agregados a M5",
      "category": "aggregated"
    }
  }
}
```

## âœ… Validaciones Implementadas

### **ValidaciÃ³n de Valores**
- âœ… Verificar que `data_origin` estÃ© en el catÃ¡logo permitido
- âœ… Verificar que no hay valores nulos
- âœ… Verificar que `quality_score` estÃ© en rango vÃ¡lido (0.0-1.0)

### **ValidaciÃ³n de Formato**
- âœ… Verificar que `time` sea datetime vÃ¡lido
- âœ… Verificar que `time` sea timezone-aware (UTC)
- âœ… Verificar columnas requeridas presentes

### **ValidaciÃ³n de LÃ³gica**
- âœ… Verificar que `high >= low`
- âœ… Verificar que `open` y `close` estÃ©n entre `high` y `low`
- âœ… Verificar que precios sean positivos

## ğŸš€ Uso en el Pipeline

### **1. Captura de Datos**
```python
# En hpc_capture.py
traceability_manager = DataTraceabilityManager()
df = traceability_manager.assign_data_origin(
    df, capture_method='rates_range', source_timeframe='M5'
)
```

### **2. Procesamiento de Datos**
```python
# En processing.py
def process_ticks_to_ohlc(ticks_df):
    # ... procesamiento ...
    result_df = traceability_manager.assign_data_origin(
        result_df,
        capture_method='aggregation',
        source_timeframe='ticks'
    )
```

### **3. ImputaciÃ³n de Gaps**
```python
# En processing.py
def brownian_bridge_imputation(df):
    # ... imputaciÃ³n ...
    imputed_df = traceability_manager.assign_data_origin(
        imputed_df,
        capture_method='brownian_bridge',
        source_timeframe='imputed',
        is_imputed=True,
        imputation_method='brownian_bridge'
    )
```

### **4. ValidaciÃ³n Antes de Guardar**
```python
# ValidaciÃ³n automÃ¡tica
is_valid, errors = traceability_manager.validate_data_origin(df)
if not is_valid:
    logger.error(f"Errores de validaciÃ³n: {errors}")
    raise ValueError("Datos no vÃ¡lidos")
```

## ğŸ“‹ Checklist de ImplementaciÃ³n

### **Fase 1: PreparaciÃ³n** âœ…
- [x] Definir catÃ¡logo de valores `DATA_ORIGINS`
- [x] Crear constantes de configuraciÃ³n
- [x] Implementar `DataTraceabilityManager`

### **Fase 2: IntegraciÃ³n** âœ…
- [x] Actualizar `processing.py`
- [x] Actualizar `hpc_capture.py`
- [x] Actualizar funciones de imputaciÃ³n

### **Fase 3: MigraciÃ³n** âœ…
- [x] Crear script de validaciÃ³n
- [x] Crear script de migraciÃ³n
- [x] Implementar conversiÃ³n legacy

### **Fase 4: ValidaciÃ³n** âœ…
- [x] Implementar validaciones robustas
- [x] Crear reportes de calidad
- [x] Documentar uso

### **Fase 5: Testing** ğŸ”„
- [ ] Probar con datos existentes
- [ ] Validar migraciÃ³n automÃ¡tica
- [ ] Verificar reportes de calidad

## ğŸ¯ Beneficios Implementados

### **Para Desarrolladores**
- âœ… **CÃ³digo mÃ¡s limpio**: Una sola columna en lugar de mÃºltiples
- âœ… **Menos errores**: ValidaciÃ³n automÃ¡tica de valores
- âœ… **Mejor mantenibilidad**: Constantes centralizadas

### **Para Analistas**
- âœ… **Trazabilidad completa**: Saber exactamente el origen de cada dato
- âœ… **Reportes detallados**: AnÃ¡lisis por categorÃ­a y calidad
- âœ… **AuditorÃ­a robusta**: Historial completo de procesamiento

### **Para Operaciones**
- âœ… **ValidaciÃ³n automÃ¡tica**: Detectar problemas antes de usar datos
- âœ… **MigraciÃ³n sin pÃ©rdida**: ConversiÃ³n automÃ¡tica de datos legacy
- âœ… **EstÃ¡ndares consistentes**: Formato uniforme en todo el pipeline

## ğŸ”® PrÃ³ximos Pasos

### **Inmediatos**
1. **Testing exhaustivo** con datos reales
2. **MigraciÃ³n de datasets** existentes
3. **ValidaciÃ³n de reportes** de calidad

### **Mediano Plazo**
1. **IntegraciÃ³n con ML pipeline** para tracking de features
2. **Dashboard de calidad** en tiempo real
3. **Alertas automÃ¡ticas** para datos de baja calidad

### **Largo Plazo**
1. **Trazabilidad de features** tÃ©cnicos
2. **Versionado de datasets** con metadata completa
3. **Compliance y auditorÃ­a** regulatoria

---

## ğŸ“ Soporte

Para preguntas sobre la implementaciÃ³n:
- Revisar `pipelines/01_capture/utils/data_traceability.py`
- Consultar `pipelines/01_capture/config/constants.py`
- Usar script de validaciÃ³n: `validate_traceability.py`

**Â¡La nueva estructura de trazabilidad estÃ¡ lista para uso en producciÃ³n!** ğŸš€ 