# Gu√≠a de Implementaci√≥n: Trazabilidad y Auditor√≠a de Datos

## üìã Resumen Ejecutivo

Este documento describe la implementaci√≥n de un **sistema estandarizado de trazabilidad y auditor√≠a de datos** para el pipeline de trading. La nueva estructura reemplaza el sistema legacy de m√∫ltiples columnas con una **columna √∫nica estandarizada `data_origin`** que proporciona trazabilidad completa del origen y calidad de cada registro.

## üéØ Objetivos Implementados

‚úÖ **Estandarizaci√≥n**: Una sola columna `data_origin` con valores catalogados  
‚úÖ **Trazabilidad completa**: Origen, m√©todo de captura, calidad y procesamiento  
‚úÖ **Validaci√≥n robusta**: Verificaci√≥n autom√°tica de valores permitidos  
‚úÖ **Migraci√≥n autom√°tica**: Conversi√≥n de datos legacy a nueva estructura  
‚úÖ **Reportes avanzados**: An√°lisis detallado de calidad y origen de datos  
‚úÖ **Formato de tiempo est√°ndar**: UTC con zona horaria expl√≠cita  

## üèóÔ∏è Arquitectura de la Nueva Estructura

### **Columna Principal: `data_origin`**

La columna `data_origin` contiene valores estandarizados que codifican toda la informaci√≥n de trazabilidad:

```
FORMATO: [TIMEFRAME]_[TIPO]_[METODO]
Ejemplos:
- M5_NATIVO          ‚Üí Datos M5 capturados directamente
- M5_AGREGADO_M1     ‚Üí Datos M1 agregados a M5
- M5_IMPUTADO_BROWNIAN ‚Üí Datos imputados con Brownian Bridge
- TICKS_NATIVO       ‚Üí Datos de ticks capturados directamente
```

### **Cat√°logo de Valores Permitidos**

#### **Datos Nativos (Captura Directa)**
| Valor | Descripci√≥n | Quality Score | Categor√≠a |
|-------|-------------|---------------|-----------|
| `M5_NATIVO` | Datos capturados directamente en M5 | 1.0 | native |
| `M1_NATIVO` | Datos capturados directamente en M1 | 0.95 | native |
| `M10_NATIVO` | Datos capturados directamente en M10 | 0.85 | native |
| `M15_NATIVO` | Datos capturados directamente en M15 | 0.80 | native |
| `M20_NATIVO` | Datos capturados directamente en M20 | 0.75 | native |
| `M30_NATIVO` | Datos capturados directamente en M30 | 0.70 | native |
| `H1_NATIVO` | Datos capturados directamente en H1 | 0.65 | native |
| `TICKS_NATIVO` | Datos de ticks capturados directamente | 0.98 | native |

#### **Datos Agregados (Resampleados)**
| Valor | Descripci√≥n | Quality Score | Categor√≠a |
|-------|-------------|---------------|-----------|
| `M5_AGREGADO_M1` | Datos M1 agregados a M5 | 0.95 | aggregated |
| `M5_AGREGADO_M10` | Datos M10 agregados a M5 | 0.85 | aggregated |
| `M5_AGREGADO_M15` | Datos M15 agregados a M5 | 0.80 | aggregated |
| `M5_AGREGADO_M20` | Datos M20 agregados a M5 | 0.75 | aggregated |
| `M5_AGREGADO_M30` | Datos M30 agregados a M5 | 0.70 | aggregated |
| `M5_AGREGADO_H1` | Datos H1 agregados a M5 | 0.65 | aggregated |
| `M5_AGREGADO_TICKS` | Datos de ticks agregados a M5 | 0.98 | aggregated |

#### **Datos Imputados (Sint√©ticos)**
| Valor | Descripci√≥n | Quality Score | Categor√≠a |
|-------|-------------|---------------|-----------|
| `M5_IMPUTADO_BROWNIAN` | Datos imputados usando Brownian Bridge | 0.7 | imputed |
| `M5_IMPUTADO_INTERPOLADO` | Datos imputados usando interpolaci√≥n lineal | 0.6 | imputed |
| `M5_IMPUTADO_SIMPLE` | Datos imputados usando m√©todo simple | 0.5 | imputed |
| `M5_IMPUTADO_GAUSSIANO` | Datos imputados usando distribuci√≥n gaussiana | 0.65 | imputed |

#### **Otros Tipos**
| Valor | Descripci√≥n | Quality Score | Categor√≠a |
|-------|-------------|---------------|-----------|
| `M5_FUERA_DE_HORARIO` | Datos fuera del horario de mercado | 0.3 | outside_market |
| `M5_FALLBACK` | Datos capturados usando m√©todo de respaldo | 0.8 | fallback |
| `DESCONOCIDO` | Origen de datos desconocido | 0.0 | unknown |

## üîß Implementaci√≥n T√©cnica

### **1. Constantes y Configuraci√≥n**

```python
# pipelines/01_capture/config/constants.py

# Cat√°logo de valores permitidos
DATA_ORIGINS = {
    'M5_NATIVO': {
        'description': 'Datos capturados directamente en M5 (m√°xima calidad)',
        'quality_score': 1.0,
        'category': 'native'
    },
    # ... m√°s valores
}

# Lista para validaci√≥n
DATA_ORIGIN_VALUES = list(DATA_ORIGINS.keys())

# Mapeo de m√©todos de captura
CAPTURE_METHOD_TO_DATA_ORIGIN = {
    'rates_range': {
        'M5': 'M5_NATIVO',
        'M1': 'M1_NATIVO',
        # ...
    }
}
```

### **2. Gestor de Trazabilidad**

```python
# pipelines/01_capture/utils/data_traceability.py

class DataTraceabilityManager:
    def assign_data_origin(self, df, capture_method, source_timeframe, 
                          is_imputed=False, imputation_method=None):
        """Asignar data_origin estandarizado"""
        
    def validate_data_origin(self, df):
        """Validar valores de data_origin"""
        
    def convert_legacy_data_flags(self, df):
        """Migrar datos legacy a nueva estructura"""
```

### **3. Integraci√≥n en Procesamiento**

```python
# pipelines/01_capture/data/processing.py

def brownian_bridge_imputation_numba_tracked(df, quality_tracker):
    # Inicializar gestor de trazabilidad
    traceability_manager = DataTraceabilityManager()
    
    # ... l√≥gica de imputaci√≥n ...
    
    # Asignar data_origin estandarizado
    imputed_df = traceability_manager.assign_data_origin(
        imputed_df, 
        capture_method='brownian_bridge',
        source_timeframe='imputed',
        is_imputed=True,
        imputation_method='brownian_bridge'
    )
```

## üìä Estructura de Datos Final

### **Columnas Requeridas**
```python
REQUIRED_COLUMNS = [
    'time',           # Timestamp en UTC
    'open',           # Precio de apertura
    'high',           # Precio m√°ximo
    'low',            # Precio m√≠nimo
    'close',          # Precio de cierre
    'data_origin'     # Origen estandarizado del dato
]
```

### **Columnas Opcionales**
```python
OPTIONAL_COLUMNS = [
    'tick_volume',    # Volumen de ticks
    'spread',         # Spread
    'real_volume',    # Volumen real
    'quality_score'   # Puntuaci√≥n de calidad (0.0-1.0)
]
```

### **Formato de Tiempo Est√°ndar**
```python
TIME_FORMAT_CONFIG = {
    'display_format': '%Y-%m-%d %H:%M:%S',
    'display_format_with_tz': '%Y-%m-%d %H:%M:%S%z',
    'default_timezone': 'UTC'
}
```

## üîÑ Migraci√≥n de Datos Legacy

### **Columnas Legacy a Migrar**
- `data_flag` ‚Üí `data_origin`
- `source_timeframe` ‚Üí Informaci√≥n codificada en `data_origin`
- `capture_method` ‚Üí Informaci√≥n codificada en `data_origin`

### **Script de Migraci√≥n**

```bash
# Validar archivos existentes
python pipelines/01_capture/utils/validate_traceability.py \
    --input data/ \
    --action validate \
    --report validation_report.json

# Migrar archivos legacy
python pipelines/01_capture/utils/validate_traceability.py \
    --input data/ \
    --output data_migrated/ \
    --action migrate \
    --pattern "*.parquet"
```

### **Mapeo de Migraci√≥n**

```python
# Ejemplos de migraci√≥n autom√°tica
'data_flag': 'real_m5' + 'source_timeframe': 'M5' 
    ‚Üí 'data_origin': 'M5_NATIVO'

'data_flag': 'aggregated_from_m1' + 'source_timeframe': 'M1'
    ‚Üí 'data_origin': 'M5_AGREGADO_M1'

'data_flag': 'imputed_brownian' + 'capture_method': 'brownian_bridge'
    ‚Üí 'data_origin': 'M5_IMPUTADO_BROWNIAN'
```

## üìà Reportes de Calidad Mejorados

### **An√°lisis por Categor√≠a**
```json
{
  "category_analysis": {
    "native": {
      "count": 150000,
      "percentage": 75.0,
      "description": "Datos capturados directamente"
    },
    "aggregated": {
      "count": 40000,
      "percentage": 20.0,
      "description": "Datos resampleados"
    },
    "imputed": {
      "count": 10000,
      "percentage": 5.0,
      "description": "Datos sint√©ticos"
    }
  }
}
```

### **Distribuci√≥n por Origen**
```json
{
  "origin_breakdown": {
    "M5_NATIVO": {
      "count": 120000,
      "percentage": 60.0,
      "description": "Datos capturados directamente en M5",
      "category": "native"
    },
    "M5_AGREGADO_M1": {
      "count": 30000,
      "percentage": 15.0,
      "description": "Datos M1 agregados a M5",
      "category": "aggregated"
    }
  }
}
```

## ‚úÖ Validaciones Implementadas

### **Validaci√≥n de Valores**
- ‚úÖ Verificar que `data_origin` est√© en el cat√°logo permitido
- ‚úÖ Verificar que no hay valores nulos
- ‚úÖ Verificar que `quality_score` est√© en rango v√°lido (0.0-1.0)

### **Validaci√≥n de Formato**
- ‚úÖ Verificar que `time` sea datetime v√°lido
- ‚úÖ Verificar que `time` sea timezone-aware (UTC)
- ‚úÖ Verificar columnas requeridas presentes

### **Validaci√≥n de L√≥gica**
- ‚úÖ Verificar que `high >= low`
- ‚úÖ Verificar que `open` y `close` est√©n entre `high` y `low`
- ‚úÖ Verificar que precios sean positivos

## üöÄ Uso en el Pipeline

### **1. Captura de Datos**
```python
# En hpc_capture.py
traceability_manager = DataTraceabilityManager()
df = traceability_manager.assign_data_origin(
    df, capture_method='rates_range', source_timeframe='M5'
)
```

### **2. Procesamiento de Datos**
```python
# En processing.py
def process_ticks_to_ohlc(ticks_df):
    # ... procesamiento ...
    result_df = traceability_manager.assign_data_origin(
        result_df,
        capture_method='aggregation',
        source_timeframe='ticks'
    )
```

### **3. Imputaci√≥n de Gaps**
```python
# En processing.py
def brownian_bridge_imputation(df):
    # ... imputaci√≥n ...
    imputed_df = traceability_manager.assign_data_origin(
        imputed_df,
        capture_method='brownian_bridge',
        source_timeframe='imputed',
        is_imputed=True,
        imputation_method='brownian_bridge'
    )
```

### **4. Validaci√≥n Antes de Guardar**
```python
# Validaci√≥n autom√°tica
is_valid, errors = traceability_manager.validate_data_origin(df)
if not is_valid:
    logger.error(f"Errores de validaci√≥n: {errors}")
    raise ValueError("Datos no v√°lidos")
```

## üìã Checklist de Implementaci√≥n

### **Fase 1: Preparaci√≥n** ‚úÖ
- [x] Definir cat√°logo de valores `DATA_ORIGINS`
- [x] Crear constantes de configuraci√≥n
- [x] Implementar `DataTraceabilityManager`

### **Fase 2: Integraci√≥n** ‚úÖ
- [x] Actualizar `processing.py`
- [x] Actualizar `hpc_capture.py`
- [x] Actualizar funciones de imputaci√≥n

### **Fase 3: Migraci√≥n** ‚úÖ
- [x] Crear script de validaci√≥n
- [x] Crear script de migraci√≥n
- [x] Implementar conversi√≥n legacy

### **Fase 4: Validaci√≥n** ‚úÖ
- [x] Implementar validaciones robustas
- [x] Crear reportes de calidad
- [x] Documentar uso

### **Fase 5: Testing** üîÑ
- [ ] Probar con datos existentes
- [ ] Validar migraci√≥n autom√°tica
- [ ] Verificar reportes de calidad

## üéØ Beneficios Implementados

### **Para Desarrolladores**
- ‚úÖ **C√≥digo m√°s limpio**: Una sola columna en lugar de m√∫ltiples
- ‚úÖ **Menos errores**: Validaci√≥n autom√°tica de valores
- ‚úÖ **Mejor mantenibilidad**: Constantes centralizadas

### **Para Analistas**
- ‚úÖ **Trazabilidad completa**: Saber exactamente el origen de cada dato
- ‚úÖ **Reportes detallados**: An√°lisis por categor√≠a y calidad
- ‚úÖ **Auditor√≠a robusta**: Historial completo de procesamiento

### **Para Operaciones**
- ‚úÖ **Validaci√≥n autom√°tica**: Detectar problemas antes de usar datos
- ‚úÖ **Migraci√≥n sin p√©rdida**: Conversi√≥n autom√°tica de datos legacy
- ‚úÖ **Est√°ndares consistentes**: Formato uniforme en todo el pipeline

## üîÆ Pr√≥ximos Pasos

### **Inmediatos**
1. **Testing exhaustivo** con datos reales
2. **Migraci√≥n de datasets** existentes
3. **Validaci√≥n de reportes** de calidad

### **Mediano Plazo**
1. **Integraci√≥n con ML pipeline** para tracking de features
2. **Dashboard de calidad** en tiempo real
3. **Alertas autom√°ticas** para datos de baja calidad

### **Largo Plazo**
1. **Trazabilidad de features** t√©cnicos
2. **Versionado de datasets** con metadata completa
3. **Compliance y auditor√≠a** regulatoria

---

## üìû Soporte

Para preguntas sobre la implementaci√≥n:
- Revisar `pipelines/01_capture/utils/data_traceability.py`
- Consultar `pipelines/01_capture/config/constants.py`
- Usar script de validaci√≥n: `validate_traceability.py`

**¬°La nueva estructura de trazabilidad est√° lista para uso en producci√≥n!** üöÄ 